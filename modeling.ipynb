{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from ridgeplot import ridgeplot\n",
    "import plotly.express as px\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 8927\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/writing_center_v2.csv\")\n",
    "df.rename(columns={'Ethnicity_Hispanic / Latino':'Ethnicity_Hispanic', 'Ethnicity_Mixed Ethnicity':'Ethnicity_Mixed','Ethnicity_White, Non-Hispanic':'Ethnicity_White'},inplace=True)\n",
    "df['Main_Course_SuccessFlag'] = df['Main_Course_SuccessFlag'].astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parameters(trace, features, trace_plot=True, forest_plot=True):\n",
    "  '''\n",
    "  Can be used for complete-pooling, no-pooling and multilevel.\n",
    "  '''\n",
    "  features_to_include = ['beta_' + feature for feature in features]\n",
    "  if trace_plot:\n",
    "    az.plot_trace(trace, var_names=[\"beta0\"] + features_to_include)\n",
    "  if forest_plot:\n",
    "    az.plot_forest(trace, var_names=[\"beta0\"] + features_to_include, combined=True)\n",
    "\n",
    "def plot_latent_parameters(trace, features, trace_plot=True, forest_plot=True):\n",
    "  '''\n",
    "  Can only be used for multilevel.\n",
    "  '''\n",
    "  features_to_include_mu = ['beta_' + feature  + '_mu' for feature in features]\n",
    "  features_to_include_sigma = ['beta_' + feature + '_sigma' for feature in features]\n",
    "  if trace_plot:\n",
    "    az.plot_trace(trace, var_names=[\"mu_beta0\", \"sigma_beta0\"] + features_to_include_mu + features_to_include_sigma)\n",
    "  if forest_plot:\n",
    "    az.plot_forest(trace, var_names=[\"mu_beta0\", \"sigma_beta0\"] + features_to_include_mu + features_to_include_sigma, combined=True)\n",
    "\n",
    "def plot_structure(model):\n",
    "  '''\n",
    "  Can be used for complete-pooling, no-pooling and multilevel.\n",
    "  '''\n",
    "  pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pooling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_pooling(features, df, save_name:str, rng, cv=False):\n",
    "  coords = {\"obs_id\": df.index.values}\n",
    "\n",
    "  with pm.Model(coords=coords) as binomial_regression_model:\n",
    "      # Define the design matrix (X)\n",
    "      X = pm.Data(\"X\", df[features].values,\n",
    "                  dims=[\"obs_id\", \"predictor\"])\n",
    "\n",
    "      # Priors\n",
    "      beta0 = pm.Normal(\"beta0\", mu=0, sigma=10)\n",
    "\n",
    "      beta_distributions = {}\n",
    "      # Create Normal distributions dynamically\n",
    "      for feature in features:\n",
    "          beta_name = 'beta_' + feature\n",
    "          beta_distributions[beta_name] = pm.Normal(str(beta_name), mu=0, sigma=10)\n",
    "\n",
    "      # Linear model with beta0 + linear combination of features-coefficients and feature-data\n",
    "      mu = beta0\n",
    "      for feature in features:\n",
    "        mu += beta_distributions['beta_' + feature] * X[:, features.index(feature)]\n",
    "\n",
    "      p = pm.Deterministic(\"p\", pm.math.invlogit(mu), dims=\"obs_id\")\n",
    "\n",
    "      # Likelihood\n",
    "      pm.Binomial(\"y\", n=1, p=p, observed=df[\"Main_Course_SuccessFlag\"], dims=\"obs_id\")\n",
    "\n",
    "\n",
    "  # Inference\n",
    "  with binomial_regression_model:\n",
    "      trace = pm.sample(2000, tune=1000,return_inferencedata=True, random_seed=rng)\n",
    "      pm.compute_log_likelihood(trace) # used for model comparison\n",
    "  \n",
    "      if cv == False:  \n",
    "        #save trace\n",
    "        trace.to_netcdf(\"./traces/\"+save_name+\"_complete_pooling.nc\")\n",
    "\n",
    "  return trace, binomial_regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Pooling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_pooling(features, df, save_name:str, rng, cv=False):\n",
    "    instructor_idxs, instructors = pd.factorize(df.Instructor_ID)\n",
    "    num_instructors = len(instructors)\n",
    "\n",
    "    coords = {\n",
    "        \"instructor\": instructors,\n",
    "        \"obs_id\": np.arange(len(instructor_idxs)),\n",
    "        \"predictor\": features\n",
    "    }\n",
    "\n",
    "    with pm.Model(coords=coords) as binomial_regression_model:\n",
    "        # Define instructor\n",
    "        instructor_idx = pm.Data(\"instructor_idx\", instructor_idxs, dims=\"obs_id\")\n",
    "\n",
    "        # Define the design matrix (X) with instructor-specific predictors\n",
    "        X = pm.Data(\"X\", df[features].values, dims=[\"obs_id\", \"predictor\"])\n",
    "\n",
    "        # Priors\n",
    "        beta0 = pm.Normal(\"beta0\", 0, sigma=10, dims=\"instructor\")  # intercept varying by instructor\n",
    "\n",
    "        beta_distributions = {}\n",
    "        # Create Normal distributions dynamically\n",
    "        for feature in features:\n",
    "            beta_name = 'beta_' + feature\n",
    "            beta_distributions[beta_name] = pm.Normal(str(beta_name), 0, sigma=10, dims=\"instructor\")  # all betas varying by instructor\n",
    "\n",
    "        # Linear model\n",
    "        mu = beta0[instructor_idx]\n",
    "        for feature in features:\n",
    "            mu += beta_distributions['beta_' + feature][instructor_idx] * X[:, features.index(feature)]\n",
    "\n",
    "        p = pm.Deterministic(\"p\", pm.math.invlogit(mu), dims=\"obs_id\")\n",
    "\n",
    "        # Likelihood\n",
    "        pm.Binomial(\"y\", n=1, p=p, observed=df[\"Main_Course_SuccessFlag\"], dims=\"obs_id\")\n",
    "\n",
    "    # Inference\n",
    "    with binomial_regression_model:\n",
    "        trace = pm.sample(2000, tune=1000, return_inferencedata=True, random_seed=rng)\n",
    "        pm.compute_log_likelihood(trace)  # used for model comparison\n",
    "    \n",
    "        if cv == False:\n",
    "            #save trace\n",
    "            trace.to_netcdf(\"./traces/\"+save_name+\"_no_pooling.nc\")\n",
    "    return trace, binomial_regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilevel Functions (Hierarchical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilevel(features, df, save_name:str, rng, cv=False):\n",
    "    instructor_idxs, instructors = pd.factorize(df.Instructor_ID)\n",
    "    num_instructors = len(instructors)\n",
    "\n",
    "    coords = {\n",
    "        \"instructor\": instructors,\n",
    "        \"obs_id\": np.arange(len(instructor_idxs)),\n",
    "        \"predictor\": features\n",
    "    }\n",
    "\n",
    "    with pm.Model(coords=coords) as binomial_regression_model:\n",
    "        # Define instructor\n",
    "        instructor_idx = pm.Data(\"instructor_idx\", instructor_idxs, dims=\"obs_id\")\n",
    "\n",
    "        # Define the design matrix (X) with instructor-specific predictors\n",
    "        X = pm.Data(\"X\", df[features].values, dims=[\"obs_id\", \"predictor\"])\n",
    "\n",
    "        # Hyperpriors for instructor intercept\n",
    "        mu_beta0 = pm.Normal(\"mu_beta0\", mu=0.0, sigma=1)\n",
    "        sigma_beta0 = pm.HalfNormal(\"sigma_beta0\", 1)\n",
    "        # Hyperpriors for intructor betas\n",
    "        hyperpriors_mu = {}\n",
    "        hyperpriors_sigma =  {}\n",
    "        for feature in features:\n",
    "            beta_name = 'beta_' + feature\n",
    "            hyperpriors_mu[beta_name] = pm.Normal(str(beta_name)+'_mu', mu=0, sigma=1)\n",
    "            hyperpriors_sigma[beta_name] = pm.HalfNormal(str(beta_name)+'_sigma', 1)\n",
    "\n",
    "        # Priors\n",
    "        beta0 = pm.Normal(\"beta0\", mu_beta0, sigma_beta0, dims=\"instructor\")  # mu and sigma follows from multilevel and intercept varying by instructor\n",
    "        beta_distributions = {}\n",
    "        # Create Normal distributions dynamically\n",
    "        for feature in features:\n",
    "            beta_name = 'beta_' + feature\n",
    "            beta_distributions[beta_name] = pm.Normal(str(beta_name),\n",
    "                                                      mu = hyperpriors_mu[beta_name], #mu follows from multilevel\n",
    "                                                      sigma=hyperpriors_sigma[beta_name], # sigma follows from multilevel\n",
    "                                                      dims=\"instructor\")  # all betas varying by instructor\n",
    "        # Linear model\n",
    "        mu = beta0[instructor_idx]\n",
    "        for feature in features:\n",
    "            mu += beta_distributions['beta_' + feature][instructor_idx] * X[:, features.index(feature)]\n",
    "\n",
    "        p = pm.Deterministic(\"p\", pm.math.invlogit(mu), dims=\"obs_id\")\n",
    "\n",
    "        # Likelihood\n",
    "        pm.Binomial(\"y\", n=1, p=p, observed=df[\"Main_Course_SuccessFlag\"], dims=\"obs_id\")\n",
    "\n",
    "    # Inference\n",
    "    with binomial_regression_model:\n",
    "        trace = pm.sample(6000, tune=2000, return_inferencedata=True, random_seed=rng)\n",
    "        pm.compute_log_likelihood(trace)  # used for model comparison\n",
    "    \n",
    "        if cv == False:\n",
    "            #save trace\n",
    "            trace.to_netcdf(\"./traces/\"+save_name+\"_multilevel.nc\")\n",
    "\n",
    "    return trace, binomial_regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c - 5 fold CV Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log loss\n",
    "# https://medium.com/analytics-vidhya/binary-crossentropy-in-its-core-35bcecf27a8a\n",
    "def binary_cross_entropy_loss(true, predicted):\n",
    "  binary_cross_entropy = -np.mean(true * np.log(predicted) + (1 - true) * np.log(1 - predicted))\n",
    "  return binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_error(features, df, complete_pooling_=True, no_pooling_=True, multilevel_=True):\n",
    "  # Create StratifiedKFold object with 5 folds\n",
    "  target_instructor_stratify = df[\"Main_Course_SuccessFlag\"].astype(str) + \"_\" + df[\"Instructor_ID\"].astype(str)\n",
    "  stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "  losses_complete_pooling = []\n",
    "  losses_no_pooling = []\n",
    "  losses_multilevel = []\n",
    "\n",
    "  # Iterate over the folds\n",
    "  for fold, (train_index, test_index) in enumerate(stratified_kfold.split(df[features], target_instructor_stratify)):\n",
    "        train_data = df.iloc[train_index]\n",
    "        test_data = df.iloc[test_index]\n",
    "        test_features = test_data[features+['Instructor_ID']]\n",
    "        test_target = test_data[['Main_Course_SuccessFlag', 'Instructor_ID']]\n",
    "\n",
    "\n",
    "        ######################### Complete Pooling ###########################\n",
    "        if complete_pooling_:\n",
    "          trace_train, model_train = complete_pooling(features, train_data, 'fill', cv=True)\n",
    "          #grab posterior mean betas for the features - takes quite some time\n",
    "          posterior_mean_beta0 = pm.summary(trace_train)['mean']['beta0']\n",
    "          posterior_mean_betas = {}\n",
    "          for feature in features:\n",
    "            beta_name = 'beta_' + feature\n",
    "            posterior_mean_betas[beta_name] = pm.summary(trace_train)['mean'][beta_name]\n",
    "          # make the predictions on the test_features\n",
    "          log_odds_predictions = posterior_mean_beta0\n",
    "          for feature in features:\n",
    "            log_odds_predictions += posterior_mean_betas['beta_' + feature] * test_features[feature] # dot product of betas and test_features\n",
    "          prob_predictions = 1 / (1 + np.exp(-log_odds_predictions))\n",
    "          loss = binary_cross_entropy_loss(test_target.loc[:,'Main_Course_SuccessFlag'], prob_predictions)\n",
    "          losses_complete_pooling.append(loss)\n",
    "\n",
    "        #################### No-pooling #######################\n",
    "        if no_pooling_:\n",
    "          trace_train, model_train = no_pooling(features, train_data, 'fill', cv=True)\n",
    "          for instructor in df['Instructor_ID'].unique().tolist():\n",
    "            posterior_mean_beta0 = pm.summary(trace_train)['mean']['beta0['+str(instructor)+']']\n",
    "            posterior_mean_betas = {}\n",
    "            for feature in features:\n",
    "              beta_name = 'beta_' + feature + '[' + str(instructor) + ']'\n",
    "              posterior_mean_betas[beta_name] = pm.summary(trace_train)['mean'][beta_name]\n",
    "            # make the predictions on the test_features\n",
    "            log_odds_predictions = posterior_mean_beta0\n",
    "            for feature in features:\n",
    "              log_odds_predictions += posterior_mean_betas['beta_' + feature + '[' + str(instructor) + ']'] * test_features[test_features['Instructor_ID']==instructor][feature] # dot product of betas and test_features for instructor\n",
    "            prob_predictions = 1 / (1 + np.exp(-log_odds_predictions))\n",
    "            loss = binary_cross_entropy_loss(test_target[test_target['Instructor_ID']==instructor]['Main_Course_SuccessFlag'], prob_predictions) # loss for instructor\n",
    "            losses_no_pooling.append(loss)\n",
    "\n",
    "        #################### Multilevel #######################\n",
    "        if multilevel_:\n",
    "          trace_train, model_train = multilevel(features, train_data, 'fill', cv=True)\n",
    "          for instructor in df['Instructor_ID'].unique().tolist():\n",
    "            posterior_mean_beta0 = pm.summary(trace_train)['mean']['beta0['+str(instructor)+']']\n",
    "            posterior_mean_betas = {}\n",
    "            for feature in features:\n",
    "              beta_name = 'beta_' + feature + '[' + str(instructor) + ']'\n",
    "              posterior_mean_betas[beta_name] = pm.summary(trace_train)['mean'][beta_name]\n",
    "            # make the predictions on the test_features\n",
    "            log_odds_predictions = posterior_mean_beta0\n",
    "            for feature in features:\n",
    "              log_odds_predictions += posterior_mean_betas['beta_' + feature + '[' + str(instructor) + ']'] * test_features[test_features['Instructor_ID']==instructor][feature] # dot product of betas and test_features for instructor\n",
    "            prob_predictions = 1 / (1 + np.exp(-log_odds_predictions))\n",
    "            loss = binary_cross_entropy_loss(test_target[test_target['Instructor_ID']==instructor]['Main_Course_SuccessFlag'], prob_predictions) # loss for instructor\n",
    "            losses_multilevel.append(loss)\n",
    "\n",
    "  return losses_complete_pooling, losses_no_pooling, losses_multilevel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FITTING MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Gender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_features = ['Gender_Male', 'Gender_Female']\n",
    "# gender_complete_pooling_trace, gender_complete_pooling_model = complete_pooling(gender_features, df, 'gender',rng)\n",
    "# gender_no_pooling_trace, gender_no_pooling_model = no_pooling(gender_features, df, 'gender', rng)\n",
    "gender_multilevel_trace, gender_multilevel_model = multilevel(gender_features, df, 'gender_constrained', rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "\n",
    "# gender_complete_pooling_trace = az.from_netcdf(\"./traces/gender_complete_pooling.nc\")\n",
    "# gender_no_pooling_trace = az.from_netcdf(\"./traces/gender_no_pooling.nc\")\n",
    "# gender_multilevel_trace = az.from_netcdf(\"./traces/gender_multilevel.nc\")\n",
    "\n",
    "# ethnicity_multilevel_trace = az.from_netcdf(\"./traces/ethnicity_multilevel.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_parameters(gender_multilevel_trace, gender_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameters(gender_no_pooling_trace, gender_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Ethnicity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_features = ['Ethnicity_White', 'Ethnicity_Asian', 'Ethnicity_Hispanic', 'Ethnicity_Mixed']\n",
    "ethnicity_complete_pooling_trace, ethnicity_complete_pooling_model = complete_pooling(ethnicity_features, df, 'ethnicity', rng)\n",
    "ethnicity_no_pooling_trace, ethnicity_no_pooling_model = no_pooling(ethnicity_features, df, 'ethnicity', rng)\n",
    "ethnicity_multilevel_trace, ethnicity_multilevel_model = multilevel(ethnicity_features, df, 'ethnicity', rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameters(ethnicity_no_pooling_trace, ethnicity_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_parameters(ethnicity_multilevel_trace, ethnicity_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Adjusted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_features = ['Gender_Male', 'Gender_Female', 'Ethnicity_White', 'Ethnicity_Asian', 'Ethnicity_Hispanic', 'Ethnicity_Mixed',\n",
    "                      'Age', 'FirstGen', 'Military', 'FosterYouth', 'DSPS','FinAid', 'Units_Attempted_Beg_Of_Term', \n",
    "                      'TermUnitsAttempted', 'K12_Student', 'First_Time_College_Student', 'Nonresident_Tuition_Exempt', 'International', 'Nonresident', \n",
    "                      'WR_Center', 'Online', 'N_Center_Visits', 'Center_Attendance_Hours', 'N_Conf', 'WR_Center_FailFlag']\n",
    "# adjusted_complete_pooling_trace, adjusted_complete_pooling_model = complete_pooling(adjusted_features, df, 'adjusted', rng)\n",
    "adjusted_no_pooling_trace, adjusted_no_pooling_model = no_pooling(adjusted_features, df.iloc[0:50], 'adjusted', rng)\n",
    "# adjusted_multilevel_trace, adjusted_multilevel_model = multilevel(adjusted_features, df, 'adjusted', rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameters(adjusted_no_pooling_trace, adjusted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_parameters(adjusted_multilevel_trace, adjusted_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a & 2b Loo and WAIC from Pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.compare({'gender_complete_pooling': gender_complete_pooling_trace,\n",
    "            'gender_no_pooling': gender_no_pooling_trace,\n",
    "            'gender_multilevel': gender_multilevel_trace\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(az.compare({'gender_complete_pooling': gender_complete_pooling_trace,\n",
    "            'gender_no_pooling': gender_no_pooling_trace,\n",
    "            'gender_multilevel': gender_multilevel_trace\n",
    "            }), insample_dev=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.compare({'asian_complete_pooling': ethnicity_complete_pooling_trace,\n",
    "            'asian_no_pooling': ethnicity_no_pooling_trace,\n",
    "            'asian_multilevel': ethnicity_multilevel_trace\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(az.compare({'asian_complete_pooling': ethnicity_complete_pooling_trace,\n",
    "            'asian_no_pooling': ethnicity_no_pooling_trace,\n",
    "            'asian_multilevel': ethnicity_multilevel_trace\n",
    "            }), insample_dev=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pm.compare({'gender': trace_gender, 'white': trace_white}, ic='waic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.plot_compare(pm.compare({'gender': trace_gender, 'white': trace_white}, ic='waic'), insample_dev=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gender_complete_pooling, loss_gender_nopooling, loss_gender_multilevel = cv_error(gender_features, df, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples_list_gender = gender_multilevel_trace.posterior[\"beta_Gender_Male_sigma\"].values.tolist()\n",
    "posterior_samples_gender = []\n",
    "posterior_samples_gender.extend(posterior_samples_list_gender[0])\n",
    "posterior_samples_gender.extend(posterior_samples_list_gender[1])\n",
    "\n",
    "posterior_samples_list_asian = ethnicity_multilevel_trace.posterior[\"beta_Ethnicity_Asian_sigma\"].values.tolist()\n",
    "posterior_samples_asian = []\n",
    "posterior_samples_asian.extend(posterior_samples_list_asian[0])\n",
    "posterior_samples_asian.extend(posterior_samples_list_asian[1])\n",
    "\n",
    "\n",
    "# Create the ridge plot\n",
    "fig = ridgeplot(\n",
    "    samples=[posterior_samples_gender, posterior_samples_asian],\n",
    "    colorscale='Plotly3',\n",
    "    colormode='mean-means',  # You can adjust this based on your preference\n",
    "    linewidth=1.0,\n",
    "    spacing=1.2,\n",
    "    show_yticklabels=True,\n",
    "    xpad=0.05,\n",
    "    labels=['Gender', 'Asian']\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    width=800,\n",
    "    font_size=16,\n",
    "    plot_bgcolor=\"white\",\n",
    "    #xaxis_tickvals=[0, 1],\n",
    "    #xaxis_ticktext=[\"0\", \"1\"],\n",
    "    xaxis_gridcolor=\"rgba(0, 0, 0, 0.1)\",\n",
    "    yaxis_gridcolor=\"rgba(0, 0, 0, 0.1)\",\n",
    "    #yaxis_title=\"Assigned Probability (%)\",\n",
    "    showlegend=False,\n",
    "    title='Sigma of latent distributions'\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_gender = pm.summary(gender_no_pooling_trace)\n",
    "gender_betas = summary_gender[summary_gender.index.str.startswith(\"beta_Gender_Male\")]['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_asian = pm.summary(ethnicity_no_pooling_trace)\n",
    "asian_betas = summary_asian[summary_asian.index.str.startswith(\"beta_Ethnicity_Asian\")]['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(data):\n",
    "    B = 10000\n",
    "\n",
    "    bootstrapped_means = np.zeros(B)\n",
    "    bootstrapped_std = np.zeros(B)\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    for i in range(B):\n",
    "        # Generate a bootstrap sample by sampling with replacement\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "\n",
    "        # Calculate the mean of the bootstrap sample\n",
    "        bootstrapped_means[i] = np.mean(bootstrap_sample)\n",
    "        bootstrapped_std[i] = np.std(bootstrap_sample)\n",
    "\n",
    "    return bootstrapped_means, bootstrapped_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_means_gender_betas, bootstrap_std_gender_betas = bootstrap(gender_betas)\n",
    "bootstrap_means_asian_betas, bootstrap_std_asian_betas =  bootstrap(asian_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bootstrap_std_gender_betas, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bootstrap_std_asian_betas, bins=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
