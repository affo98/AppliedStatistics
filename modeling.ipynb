{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from ridgeplot import ridgeplot\n",
    "import plotly.express as px\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 8927\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"writing_center.csv\")\n",
    "df['Main_Course_SuccessFlag'] = df['Main_Course_SuccessFlag'].astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_variables(features):\n",
    "  df_dummy =  pd.get_dummies(df, columns=features, drop_first=False)\n",
    "  return df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = create_dummy_variables(['Gender','Ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parameters(trace, features, trace_plot=True, forest_plot=True):\n",
    "  '''\n",
    "  Can be used for complete-pooling, no-pooling and multilevel.\n",
    "  '''\n",
    "  features_to_include = ['beta_' + feature for feature in features]\n",
    "  if trace_plot:\n",
    "    az.plot_trace(trace, var_names=[\"beta0\"] + features_to_include)\n",
    "  if forest_plot:\n",
    "    az.plot_forest(trace, var_names=[\"beta0\"] + features_to_include, combined=True)\n",
    "\n",
    "def plot_latent_parameters(trace, features, trace_plot=True, forest_plot=True):\n",
    "  '''\n",
    "  Can only be used for multilevel.\n",
    "  '''\n",
    "  features_to_include_mu = ['beta_' + feature  + '_mu' for feature in features]\n",
    "  features_to_include_sigma = ['beta_' + feature + '_sigma' for feature in features]\n",
    "  if trace_plot:\n",
    "    az.plot_trace(trace, var_names=[\"mu_beta0\", \"sigma_beta0\"] + features_to_include_mu + features_to_include_sigma)\n",
    "  if forest_plot:\n",
    "    az.plot_forest(trace, var_names=[\"mu_beta0\", \"sigma_beta0\"] + features_to_include_mu + features_to_include_sigma, combined=True)\n",
    "\n",
    "def plot_structure(model):\n",
    "  '''\n",
    "  Can be used for complete-pooling, no-pooling and multilevel.\n",
    "  '''\n",
    "  pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pooling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_pooling(features, df):\n",
    "  coords = {\"obs_id\": df.index.values}\n",
    "\n",
    "  with pm.Model(coords=coords) as binomial_regression_model:\n",
    "      # Define the design matrix (X)\n",
    "      X = pm.Data(\"X\", df[features].values,\n",
    "                  dims=[\"obs_id\", \"predictor\"])\n",
    "\n",
    "      # Priors\n",
    "      beta0 = pm.Normal(\"beta0\", mu=0, sigma=1)\n",
    "\n",
    "      beta_distributions = {}\n",
    "      # Create Normal distributions dynamically\n",
    "      for feature in features:\n",
    "          beta_name = 'beta_' + feature\n",
    "          beta_distributions[beta_name] = pm.Normal(str(beta_name), mu=0, sigma=1)\n",
    "\n",
    "      # Linear model with beta0 + linear combination of features-coefficients and feature-data\n",
    "      mu = beta0\n",
    "      for feature in features:\n",
    "        mu += beta_distributions['beta_' + feature] * X[:, features.index(feature)]\n",
    "\n",
    "      p = pm.Deterministic(\"p\", pm.math.invlogit(mu), dims=\"obs_id\")\n",
    "\n",
    "      # Likelihood\n",
    "      pm.Binomial(\"y\", n=1, p=p, observed=df[\"Main_Course_SuccessFlag\"], dims=\"obs_id\")\n",
    "\n",
    "  # Inference\n",
    "  with binomial_regression_model:\n",
    "      trace = pm.sample(2000, tune=1000)\n",
    "      pm.compute_log_likelihood(trace) # used for model comparison\n",
    "\n",
    "  return trace, binomial_regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Pooling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_pooling(features, df):\n",
    "    instructor_idxs, instructors = pd.factorize(df.Instructor_ID)\n",
    "    num_instructors = len(instructors)\n",
    "\n",
    "    coords = {\n",
    "        \"instructor\": instructors,\n",
    "        \"obs_id\": np.arange(len(instructor_idxs)),\n",
    "        \"predictor\": features\n",
    "    }\n",
    "\n",
    "    with pm.Model(coords=coords) as binomial_regression_model:\n",
    "        # Define instructor\n",
    "        instructor_idx = pm.Data(\"instructor_idx\", instructor_idxs, dims=\"obs_id\")\n",
    "\n",
    "        # Define the design matrix (X) with instructor-specific predictors\n",
    "        X = pm.Data(\"X\", df[features].values, dims=[\"obs_id\", \"predictor\"])\n",
    "\n",
    "        # Priors\n",
    "        beta0 = pm.Normal(\"beta0\", 0, sigma=100, dims=\"instructor\")  # intercept varying by instructor\n",
    "\n",
    "        beta_distributions = {}\n",
    "        # Create Normal distributions dynamically\n",
    "        for feature in features:\n",
    "            beta_name = 'beta_' + feature\n",
    "            beta_distributions[beta_name] = pm.Normal(str(beta_name), 0, sigma=100, dims=\"instructor\")  # all betas varying by instructor\n",
    "\n",
    "        # Linear model\n",
    "        mu = beta0[instructor_idx]\n",
    "        for feature in features:\n",
    "            mu += beta_distributions['beta_' + feature][instructor_idx] * X[:, features.index(feature)]\n",
    "\n",
    "        p = pm.Deterministic(\"p\", pm.math.invlogit(mu), dims=\"obs_id\")\n",
    "\n",
    "        # Likelihood\n",
    "        pm.Binomial(\"y\", n=1, p=p, observed=df[\"Main_Course_SuccessFlag\"], dims=\"obs_id\")\n",
    "\n",
    "    # Inference\n",
    "    with binomial_regression_model:\n",
    "        trace = pm.sample(2000, tune=1000)\n",
    "        pm.compute_log_likelihood(trace)  # used for model comparison\n",
    "\n",
    "    return trace, binomial_regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilevel Functions (Hierarchical Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilevel(features, df):\n",
    "    instructor_idxs, instructors = pd.factorize(df.Instructor_ID)\n",
    "    num_instructors = len(instructors)\n",
    "\n",
    "    coords = {\n",
    "        \"instructor\": instructors,\n",
    "        \"obs_id\": np.arange(len(instructor_idxs)),\n",
    "        \"predictor\": features\n",
    "    }\n",
    "\n",
    "    with pm.Model(coords=coords) as binomial_regression_model:\n",
    "        # Define instructor\n",
    "        instructor_idx = pm.Data(\"instructor_idx\", instructor_idxs, dims=\"obs_id\")\n",
    "\n",
    "        # Define the design matrix (X) with instructor-specific predictors\n",
    "        X = pm.Data(\"X\", df[features].values, dims=[\"obs_id\", \"predictor\"])\n",
    "\n",
    "        # Hyperpriors for instructor intercept\n",
    "        mu_beta0 = pm.Normal(\"mu_beta0\", mu=0.0, sigma=100)\n",
    "        sigma_beta0 = pm.HalfNormal(\"sigma_beta0\", 5.0)\n",
    "        # Hyperpriors for intructor betas\n",
    "        hyperpriors_mu = {}\n",
    "        hyperpriors_sigma =  {}\n",
    "        for feature in features:\n",
    "            beta_name = 'beta_' + feature\n",
    "            hyperpriors_mu[beta_name] = pm.Normal(str(beta_name)+'_mu', mu=0, sigma=100)\n",
    "            hyperpriors_sigma[beta_name] = pm.HalfNormal(str(beta_name)+'_sigma', 5.0)\n",
    "\n",
    "        # Priors\n",
    "        beta0 = pm.Normal(\"beta0\", mu_beta0, sigma_beta0, dims=\"instructor\")  # mu and sigma follows from multilevel and intercept varying by instructor\n",
    "        beta_distributions = {}\n",
    "        # Create Normal distributions dynamically\n",
    "        for feature in features:\n",
    "            beta_name = 'beta_' + feature\n",
    "            beta_distributions[beta_name] = pm.Normal(str(beta_name),\n",
    "                                                      mu = hyperpriors_mu[beta_name], #mu follows from multilevel\n",
    "                                                      sigma=hyperpriors_sigma[beta_name], # sigma follows from multilevel\n",
    "                                                      dims=\"instructor\")  # all betas varying by instructor\n",
    "        # Linear model\n",
    "        mu = beta0[instructor_idx]\n",
    "        for feature in features:\n",
    "            mu += beta_distributions['beta_' + feature][instructor_idx] * X[:, features.index(feature)]\n",
    "\n",
    "        p = pm.Deterministic(\"p\", pm.math.invlogit(mu), dims=\"obs_id\")\n",
    "\n",
    "        # Likelihood\n",
    "        pm.Binomial(\"y\", n=1, p=p, observed=df[\"Main_Course_SuccessFlag\"], dims=\"obs_id\")\n",
    "\n",
    "    # Inference\n",
    "    with binomial_regression_model:\n",
    "        trace = pm.sample(2000, tune=1000)\n",
    "        pm.compute_log_likelihood(trace)  # used for model comparison\n",
    "\n",
    "    return trace, binomial_regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c - 5 fold CV Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log loss\n",
    "# https://medium.com/analytics-vidhya/binary-crossentropy-in-its-core-35bcecf27a8a\n",
    "def binary_cross_entropy_loss(true, predicted):\n",
    "  binary_cross_entropy = -np.mean(true * np.log(predicted) + (1 - true) * np.log(1 - predicted))\n",
    "  return binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_error(features, df, complete_pooling_=True, no_pooling_=True, multilevel_=True):\n",
    "  # Create StratifiedKFold object with 5 folds\n",
    "  target_instructor_stratify = df[\"Main_Course_SuccessFlag\"].astype(str) + \"_\" + df[\"Instructor_ID\"].astype(str)\n",
    "  stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "  losses_complete_pooling = []\n",
    "  losses_no_pooling = []\n",
    "  losses_multilevel = []\n",
    "\n",
    "  # Iterate over the folds\n",
    "  for fold, (train_index, test_index) in enumerate(stratified_kfold.split(df[features], target_instructor_stratify)):\n",
    "        train_data = df.iloc[train_index]\n",
    "        test_data = df.iloc[test_index]\n",
    "        test_features = test_data[features+['Instructor_ID']]\n",
    "        test_target = test_data[['Main_Course_SuccessFlag', 'Instructor_ID']]\n",
    "\n",
    "\n",
    "        ######################### Complete Pooling ###########################\n",
    "        if complete_pooling_:\n",
    "          trace_train, model_train = complete_pooling(features, train_data)\n",
    "          #grab posterior mean betas for the features - takes quite some time\n",
    "          posterior_mean_beta0 = pm.summary(trace_train)['mean']['beta0']\n",
    "          posterior_mean_betas = {}\n",
    "          for feature in features:\n",
    "            beta_name = 'beta_' + feature\n",
    "            posterior_mean_betas[beta_name] = pm.summary(trace_train)['mean'][beta_name]\n",
    "          # make the predictions on the test_features\n",
    "          log_odds_predictions = posterior_mean_beta0\n",
    "          for feature in features:\n",
    "            log_odds_predictions += posterior_mean_betas['beta_' + feature] * test_features[feature] # dot product of betas and test_features\n",
    "          prob_predictions = 1 / (1 + np.exp(-log_odds_predictions))\n",
    "          loss = binary_cross_entropy_loss(test_target.loc[:,'Main_Course_SuccessFlag'], prob_predictions)\n",
    "          losses_complete_pooling.append(loss)\n",
    "\n",
    "        #################### No-pooling #######################\n",
    "        if no_pooling_:\n",
    "          trace_train, model_train = no_pooling(features, train_data)\n",
    "          for instructor in df['Instructor_ID'].unique().tolist():\n",
    "            posterior_mean_beta0 = pm.summary(trace_train)['mean']['beta0['+str(instructor)+']']\n",
    "            posterior_mean_betas = {}\n",
    "            for feature in features:\n",
    "              beta_name = 'beta_' + feature + '[' + str(instructor) + ']'\n",
    "              posterior_mean_betas[beta_name] = pm.summary(trace_train)['mean'][beta_name]\n",
    "            # make the predictions on the test_features\n",
    "            log_odds_predictions = posterior_mean_beta0\n",
    "            for feature in features:\n",
    "              log_odds_predictions += posterior_mean_betas['beta_' + feature + '[' + str(instructor) + ']'] * test_features[test_features['Instructor_ID']==instructor][feature] # dot product of betas and test_features for instructor\n",
    "            prob_predictions = 1 / (1 + np.exp(-log_odds_predictions))\n",
    "            loss = binary_cross_entropy_loss(test_target[test_target['Instructor_ID']==instructor]['Main_Course_SuccessFlag'], prob_predictions) # loss for instructor\n",
    "            losses_no_pooling.append(loss)\n",
    "\n",
    "        #################### Multilevel #######################\n",
    "        if multilevel_:\n",
    "          trace_train, model_train = multilevel(features, train_data)\n",
    "          for instructor in df['Instructor_ID'].unique().tolist():\n",
    "            posterior_mean_beta0 = pm.summary(trace_train)['mean']['beta0['+str(instructor)+']']\n",
    "            posterior_mean_betas = {}\n",
    "            for feature in features:\n",
    "              beta_name = 'beta_' + feature + '[' + str(instructor) + ']'\n",
    "              posterior_mean_betas[beta_name] = pm.summary(trace_train)['mean'][beta_name]\n",
    "            # make the predictions on the test_features\n",
    "            log_odds_predictions = posterior_mean_beta0\n",
    "            for feature in features:\n",
    "              log_odds_predictions += posterior_mean_betas['beta_' + feature + '[' + str(instructor) + ']'] * test_features[test_features['Instructor_ID']==instructor][feature] # dot product of betas and test_features for instructor\n",
    "            prob_predictions = 1 / (1 + np.exp(-log_odds_predictions))\n",
    "            loss = binary_cross_entropy_loss(test_target[test_target['Instructor_ID']==instructor]['Main_Course_SuccessFlag'], prob_predictions) # loss for instructor\n",
    "            losses_multilevel.append(loss)\n",
    "\n",
    "  return losses_complete_pooling, losses_no_pooling, losses_multilevel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Gender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_features = ['Gender_Male']\n",
    "gender_complete_pooling_trace, gender_complete_pooling_model = complete_pooling(gender_features, df_dummy)\n",
    "gender_no_pooling_trace, gender_no_pooling_model = no_pooling(gender_features, df_dummy)\n",
    "gender_multilevel_trace, gender_multilevel_model = multilevel(gender_features, df_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameters(gender_no_pooling_trace, gender_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_parameters(gender_multilevel_trace, gender_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Asian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asian_features = ['Ethnicity_Asian']\n",
    "asian_complete_pooling_trace, asian_complete_pooling_model = complete_pooling(asian_features, df_dummy)\n",
    "asian_no_pooling_trace, asian_no_pooling_model = no_pooling(asian_features, df_dummy)\n",
    "asian_multilevel_trace, asian_multilevel_model = multilevel(asian_features, df_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameters(asian_no_pooling_trace, asian_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent_parameters(asian_multilevel_trace, asian_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a & 2b Loo and WAIC from Pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'az' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maz\u001b[49m\u001b[38;5;241m.\u001b[39mcompare({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_complete_pooling\u001b[39m\u001b[38;5;124m'\u001b[39m: gender_complete_pooling_trace,\n\u001b[1;32m      2\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_no_pooling\u001b[39m\u001b[38;5;124m'\u001b[39m: gender_no_pooling_trace,\n\u001b[1;32m      3\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_multilevel\u001b[39m\u001b[38;5;124m'\u001b[39m: gender_multilevel_trace\n\u001b[1;32m      4\u001b[0m             })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'az' is not defined"
     ]
    }
   ],
   "source": [
    "az.compare({'gender_complete_pooling': gender_complete_pooling_trace,\n",
    "            'gender_no_pooling': gender_no_pooling_trace,\n",
    "            'gender_multilevel': gender_multilevel_trace\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(az.compare({'gender_complete_pooling': gender_complete_pooling_trace,\n",
    "            'gender_no_pooling': gender_no_pooling_trace,\n",
    "            'gender_multilevel': gender_multilevel_trace\n",
    "            }), insample_dev=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.compare({'asian_complete_pooling': asian_complete_pooling_trace,\n",
    "            'asian_no_pooling': asian_no_pooling_trace,\n",
    "            'asian_multilevel': asian_multilevel_trace\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(az.compare({'asian_complete_pooling': asian_complete_pooling_trace,\n",
    "            'asian_no_pooling': asian_no_pooling_trace,\n",
    "            'asian_multilevel': asian_multilevel_trace\n",
    "            }), insample_dev=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pm.compare({'gender': trace_gender, 'white': trace_white}, ic='waic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.plot_compare(pm.compare({'gender': trace_gender, 'white': trace_white}, ic='waic'), insample_dev=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gender_complete_pooling, loss_gender_nopooling, loss_gender_multilevel = cv_error(gender_features, df_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "posterior_samples_list_gender = gender_multilevel_trace.posterior[\"beta_Gender_Male_sigma\"].values.tolist()\n",
    "posterior_samples_gender = []\n",
    "posterior_samples_gender.extend(posterior_samples_list_gender[0])\n",
    "posterior_samples_gender.extend(posterior_samples_list_gender[1])\n",
    "\n",
    "posterior_samples_list_asian = asian_multilevel_trace.posterior[\"beta_Ethnicity_Asian_sigma\"].values.tolist()\n",
    "posterior_samples_asian = []\n",
    "posterior_samples_asian.extend(posterior_samples_list_asian[0])\n",
    "posterior_samples_asian.extend(posterior_samples_list_asian[1])\n",
    "\n",
    "\n",
    "# Create the ridge plot\n",
    "fig = ridgeplot(\n",
    "    samples=[posterior_samples_gender, posterior_samples_asian],\n",
    "    colorscale='Plotly3',\n",
    "    colormode='mean-means',  # You can adjust this based on your preference\n",
    "    linewidth=1.0,\n",
    "    spacing=1.2,\n",
    "    show_yticklabels=True,\n",
    "    xpad=0.05,\n",
    "    labels=['Gender', 'Asian']\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    width=800,\n",
    "    font_size=16,\n",
    "    plot_bgcolor=\"white\",\n",
    "    #xaxis_tickvals=[0, 1],\n",
    "    #xaxis_ticktext=[\"0\", \"1\"],\n",
    "    xaxis_gridcolor=\"rgba(0, 0, 0, 0.1)\",\n",
    "    yaxis_gridcolor=\"rgba(0, 0, 0, 0.1)\",\n",
    "    #yaxis_title=\"Assigned Probability (%)\",\n",
    "    showlegend=False,\n",
    "    title='Sigma of latent distributions'\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_gender = pm.summary(gender_no_pooling_trace)\n",
    "gender_betas = summary_gender[summary_gender.index.str.startswith(\"beta_Gender_Male\")]['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_asian = pm.summary(asian_no_pooling_trace)\n",
    "asian_betas = summary_asian[summary_asian.index.str.startswith(\"beta_Ethnicity_Asian\")]['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(data):\n",
    "    B = 10000\n",
    "\n",
    "    bootstrapped_means = np.zeros(B)\n",
    "    bootstrapped_std = np.zeros(B)\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    for i in range(B):\n",
    "        # Generate a bootstrap sample by sampling with replacement\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "\n",
    "        # Calculate the mean of the bootstrap sample\n",
    "        bootstrapped_means[i] = np.mean(bootstrap_sample)\n",
    "        bootstrapped_std[i] = np.std(bootstrap_sample)\n",
    "\n",
    "    return bootstrapped_means, bootstrapped_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_means_gender_betas, bootstrap_std_gender_betas = bootstrap(gender_betas)\n",
    "bootstrap_means_asian_betas, bootstrap_std_asian_betas =  bootstrap(asian_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bootstrap_std_gender_betas, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bootstrap_std_asian_betas, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
