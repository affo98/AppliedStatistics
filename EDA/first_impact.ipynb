{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is first load on dataframe \"jpx-tokyo-stock-exchange-prediction/stock_list.csv'\"\n",
    "##### Overall dataset of unique stocks in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pymc as pm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../jpx-tokyo-stock-exchange-prediction/stock_list.csv')\n",
    "df.rename(columns={'Section/Products': 'Section', '33SectorName':'Sector_one', '17SectorName':'Sector_two'}, inplace=True)\n",
    "df['TradeDate'] = pd.to_datetime(df['TradeDate'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We have {len(df.SecuritiesCode.unique())} unique stocks in our dataset all with metadata in 15 additional columns : {df.shape[0]} x {df.shape[1]}.')\n",
    "print(f'We have {len(df.Section.unique())} unique sections in our dataset.')\n",
    "print(f'We have {len(df.NewMarketSegment.unique())} unique market segments in our dataset.')\n",
    "print(f'We have {len(df.Sector_one.unique())} unique 33 Sector Names in our dataset.Some are None values, for example : {list(df.Sector_one.unique())[0:5]}')\n",
    "print(f'We have {len(df.Sector_two.unique())} unique 17 Sector Names in our dataset.Some are None values, for example : {list(df.Sector_two.unique())[0:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading train_files/stock_prices.csv that is the main stock trading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp = pd.read_csv('../../jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv')\n",
    "df_sp['Date'] = pd.to_datetime(df_sp['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate a single stock to see how PACF works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security = df_sp[df_sp[\"SecuritiesCode\"] == 1376]\n",
    "print(f'Security {1376} with number of closing prices : {security.shape[0]} and missing values : {security.Close.isnull().sum()}')\n",
    "security['Close'].fillna(security['Close'].mean(), inplace=True)\n",
    "security['Close'].plot(figsize=(16,4),legend=True)\n",
    "\n",
    "# pcaf\n",
    "correlations,conf_intervals = sm.tsa.stattools.pacf(security['Close'], nlags=20, method='ywm', alpha=0.05)\n",
    "correl = correlations.tolist()[1:]\n",
    "# First lag, lag 0 is always t today so it is 1\n",
    "sm.graphics.tsa.plot_pacf(security['Close'], method=\"ywm\",lags=20,alpha=0.05)\n",
    "# sm.graphics.tsa.plot_acf(security['Close'],lags=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap betas from first 1000 stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pcaf for first 100 stocks with 20 lags\n",
    "correlation_matrix = np.zeros((len(df_sp.SecuritiesCode.unique()[0:1000]), 20))\n",
    "for i, security in enumerate(list(df_sp.SecuritiesCode.unique())[0:1000]):\n",
    "    stock = df_sp[df_sp[\"SecuritiesCode\"] == security]\n",
    "    stock['Close'].fillna(stock['Close'].mean(), inplace=True)\n",
    "    correlations, conf_intervals = sm.tsa.stattools.pacf(stock['Close'], nlags=20, method='ywm', alpha=0.05)\n",
    "    correlation_matrix[i,:] = correlations.tolist()[1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap confidence intervals for each betas:\n",
    "from scipy.stats import bootstrap\n",
    "import seaborn as sns\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "data = (correlation_matrix[:,1],)  # samples must be in a sequence\n",
    "# Bootstrap for mean\n",
    "res_mean = bootstrap(data, np.mean, confidence_level=0.95, random_state=rng)\n",
    "\n",
    "# Bootstrap for standard deviation\n",
    "res_std = bootstrap(data, np.std, confidence_level=0.95, random_state=rng)\n",
    "\n",
    "# Creating subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Histogram and KDE for bootstrap mean\n",
    "sns.histplot(res_mean.bootstrap_distribution, bins=25, kde=True, color='blue', alpha=0.7, ax=axs[0])\n",
    "axs[0].set_title('Bootstrap Distribution of Mean')\n",
    "axs[0].set_xlabel('Mean Value')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "# Histogram and KDE for bootstrap standard deviation\n",
    "sns.histplot(res_std.bootstrap_distribution, bins=25, kde=True, color='green', alpha=0.7, ax=axs[1])\n",
    "axs[1].set_title('Bootstrap Distribution of Standard Deviation')\n",
    "axs[1].set_xlabel('Standard Deviation Value')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create baseline bayesian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data for one stock:\n",
    "security = df_sp[df_sp[\"SecuritiesCode\"] == 1376]\n",
    "print(f'Security {1376} with number of closing prices : {security.shape[0]} and missing values : {security.Close.isnull().sum()}')\n",
    "security['Close'].fillna(security['Close'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the idea of lags with np.empty_like...\n",
    "So now if these were my prices:\n",
    "my_prices_example = [1,2,3,4,5] \\\n",
    "beta_t_minus_1 = [0,0,0,0,0]\\\n",
    "beta_t_minus_1[0] = np.nan -> [nan,0,0,0,0]\\\n",
    "beta_t_minus_1[1:] = my_prices_examples -> [nan, 1,2,3,4]\\\n",
    "Meaning i am trying to predict 5, given the 4 lags: 4 ,3 ,2, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your stock price data\n",
    "cp_1376 = security[\"Close\"].to_numpy()\n",
    "\n",
    "# Split the data into train and test sets (80% train, 20% test)\n",
    "split_index = int(len(cp_1376) * 0.8)\n",
    "train = cp_1376[:split_index]\n",
    "test = cp_1376[split_index:]\n",
    "\n",
    "# Function to create lagged features\n",
    "def create_lagged_features(data, n_lags=5):\n",
    "    lagged_data = np.zeros((len(data) - n_lags, n_lags))\n",
    "    for i in range(n_lags, len(data)):\n",
    "        lagged_data[i - n_lags] = data[i - n_lags:i]\n",
    "    return lagged_data\n",
    "\n",
    "# Create lagged features for train and test\n",
    "X_train = create_lagged_features(train)\n",
    "y_train = train[5:]\n",
    "X_test = create_lagged_features(test)\n",
    "y_test = test[5:]\n",
    "\n",
    "# Define the Bayesian model\n",
    "with pm.Model() as model:\n",
    "    # Priors for unknown model parameters\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=1, shape=5) # 5, as we have 5 lags\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    y_obs = pm.Normal(\"y_obs\", mu=pm.math.dot(X_train, beta), sigma=sigma, observed=y_train)\n",
    "\n",
    "    # Sample from the posterior\n",
    "    trace = pm.sample(1000, return_inferencedata=True)\n",
    "\n",
    "# Analyze the results\n",
    "pm.plot_trace(trace)\n",
    "\n",
    "# Predictions on test set\n",
    "beta_samples = trace.posterior[\"beta\"].values.reshape(-1, 5)\n",
    "predictions = np.dot(X_test, beta_samples.T)  # Using matrix multiplication for predictions\n",
    "\n",
    "# Calculate the mean and credible interval for the predictions\n",
    "pred_mean = np.mean(predictions, axis=1)\n",
    "pred_hpd = np.percentile(predictions, [5, 95], axis=1)  # Ensure this is calculated for each prediction\n",
    "\n",
    "#pred_hpd = np.array(), np.array()\n",
    "#pred_hpd = lower 95% confidence interval, upper 95% confidence interval\n",
    "\n",
    "# Calculate the error margins\n",
    "lower_error = pred_mean - pred_hpd[0, :]\n",
    "upper_error = pred_hpd[1, :] - pred_mean\n",
    "\n",
    "# Assuming y_test is the correct length, adjust the range accordingly\n",
    "x_range = range(len(y_test))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_range, y_test, label='Actual Data', color='blue')  # Plot the actual data\n",
    "plt.plot(x_range, pred_mean, label='Predicted Mean', color='red')  # Plot the mean prediction\n",
    "\n",
    "# Plot the error margins as filled areas\n",
    "plt.fill_between(x_range, pred_mean - lower_error, pred_mean + upper_error, color='red', alpha=0.9, label='95% Credible Interval')\n",
    "\n",
    "plt.xlabel('Time (Test Set)')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.title('Actual vs Predicted Stock Prices with Error Margins (Test Set)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
