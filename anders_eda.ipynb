{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('writing_center.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 15:29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sucess is predicted by instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('instructor_encoder', OneHotEncoder(), ['Instructor_ID'])\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep any remaining columns\n",
    ")\n",
    "\n",
    "# Create a pipeline with the column transformer and logistic regression model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "model.fit(df[['Instructor_ID']], df['Main_Course_SuccessFlag'])\n",
    "\n",
    "# Print the coefficient estimates\n",
    "coefficients = model.named_steps['classifier'].coef_\n",
    "intercept = model.named_steps['classifier'].intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success predicted by writing center is different for each instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_coefs(features):\n",
    "\n",
    "    coefficients = []\n",
    "    errors = []\n",
    "    sizes = []\n",
    "\n",
    "    # Loop through unique instructor IDs\n",
    "    for ID in df['Instructor_ID'].unique().tolist():\n",
    "        df_in = df[df['Instructor_ID'] == ID]\n",
    "        sizes.append(df_in.shape[0])\n",
    "\n",
    "        # Create a logistic regression model\n",
    "        model = LogisticRegression()\n",
    "\n",
    "        model.fit(df_in[features], df_in['Main_Course_SuccessFlag'])\n",
    "\n",
    "        # Predict the probabilities\n",
    "        probabilities = model.predict_proba(df_in[features])\n",
    "\n",
    "        # Calculate log loss\n",
    "        current_log_loss = log_loss(df_in['Main_Course_SuccessFlag'], probabilities)\n",
    "\n",
    "        # Store coefficients and errors\n",
    "        coefficients.append(model.coef_[0][0])\n",
    "        errors.append(current_log_loss)\n",
    "        \n",
    "    return coefficients, errors, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(data):\n",
    "\n",
    "    #bootstrap coefficients\n",
    "    B = 10000\n",
    "\n",
    "    bootstrapped_means = np.zeros(B)\n",
    "    bootstrapped_std = np.zeros(B)\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    for i in range(B):\n",
    "        # Generate a bootstrap sample by sampling with replacement\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        \n",
    "        # Calculate the mean of the bootstrap sample\n",
    "        bootstrapped_means[i] = np.mean(bootstrap_sample)\n",
    "        bootstrapped_std[i] = np.std(bootstrap_sample)\n",
    "        \n",
    "    return bootstrapped_means, bootstrapped_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_reg, errors_reg, size_reg = model_coefs(['WR_Center'])\n",
    "coefficients_cov, errors_cov, size_cov = model_coefs(['WR_Center', 'Age', 'Military', 'FirstGen', 'FosterYouth', 'DSPS', 'FinAid', 'K12_Student', 'First_Time_College_Student', 'International', 'Nonresident'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(coefficients_reg, alpha=0.5)\n",
    "plt.hist(coefficients_cov, alpha=0.5)\n",
    "print(np.mean(coefficients_reg))\n",
    "print(np.mean(coefficients_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_means_reg, bootstrap_std_reg = bootstrap(coefficients_reg)\n",
    "bootstrap_means_cov, bootstrap_std_cov =  bootstrap(coefficients_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(bootstrap_means_reg, label='No covariates', fill=True)\n",
    "sns.kdeplot(bootstrap_means_cov, label='With covariates', fill=True)\n",
    "plt.legend()\n",
    "plt.title('Bootstrap Means of coefficient of score ~ writing_center, instructor no pooling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(bootstrap_std_reg, label='No covariates', fill=True)\n",
    "sns.kdeplot(bootstrap_std_cov, label='With covariates', fill=True)\n",
    "plt.legend()\n",
    "plt.title('Bootstrap STD of coefficient of score ~ writing_center, instructor no pooling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(errors_reg, alpha=0.5)\n",
    "plt.hist(errors_cov, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['Gender'] = label_encoder.fit_transform(df['Gender'])\n",
    "\n",
    "coefficients_gen = []\n",
    "errors_gen = []\n",
    "sizes_gen = []\n",
    "\n",
    "# Loop through unique instructor IDs\n",
    "for ID in df['Instructor_ID'].unique().tolist():\n",
    "    df_in = df[df['Instructor_ID'] == ID]\n",
    "    sizes_gen.append(df_in.shape[0])\n",
    "\n",
    "    # Create a logistic regression model\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    model.fit(df_in['Gender'].array.reshape(-1,1), df_in['Main_Course_SuccessFlag'])\n",
    "\n",
    "    # Predict the probabilities\n",
    "    probabilities = model.predict_proba(df_in['Gender'].array.reshape(-1,1))\n",
    "\n",
    "    # Calculate log loss\n",
    "    current_log_loss = log_loss(df_in['Main_Course_SuccessFlag'], probabilities)\n",
    "\n",
    "    # Store coefficients and errors\n",
    "    coefficients_gen.append(model.coef_[0][0])\n",
    "    errors_gen.append(current_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(coefficients_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(df['Gender'].array.reshape(-1,1), df['Main_Course_SuccessFlag'])\n",
    "\n",
    "# Predict the probabilities\n",
    "probabilities = model.predict_proba(df['Gender'].array.reshape(-1,1))\n",
    "\n",
    "# Calculate log loss\n",
    "log_loss_grand = log_loss(df['Main_Course_SuccessFlag'], probabilities)\n",
    "\n",
    "# Store coefficients and errors\n",
    "coef_grand = model.coef_[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.hist(coefficients_gen)\n",
    " plt.axvline(x=coef_grand, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(errors_gen)\n",
    "plt.axvline(x=log_loss_grand, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('complete pooling loss:', log_loss_grand)\n",
    "print('no pooling', np.mean(errors_gen))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
